# 随机行程时间下的车辆调度：一种近似的动态规划方法

* 作者：方希、杨洁、孟丽
* 关键词：
  * 车辆调度
  * 随机行程
  * 次延迟传播
  * 近似动态规划

## 摘要

由于意外的需求激增和供应中断，道路交通状况可能会表现出很大的不确定性，这通常会使巴士旅客遇到服务行程的开始延误，并大大降低城市交通系统的性能。
同时，信息通信技术的飞速发展为公交车队的智能调度提供了巨大的机遇。
在充分考虑延迟传播效应的情况下，本文致力于制定随机动态车辆调度问题，该问题动态调度城市公交车队以解决出行时间随机性，减少延迟并最小化公交系统的总成本。
为了解决“维数诅咒”的挑战，我们采用了近似动态规划方法（ADP），通过三层前馈神经网络来近似值函数，以便我们能够提前做出决策和解决通过顺序求解多个混合整数线性规划的贝尔曼方程。
基于北京公交线路实际运营数据集的数值例子表明，所提出的基于神经网络的 ADP 方法不仅表现出良好的学习行为，而且显着优于近视和静态策略，尤其是在出行时间随机性较高的情况下。

## 1 介绍

车辆调度在公共交通运营规划中起着关键作用，它包括线路规划、时间表、车辆调度和人员调度。
在车辆调度问题（VSP）中，给定出行时刻表的详细信息，考虑多站点、多车型等实际需求，调度公交车完成任务（时刻表出行），使得每个任务由独特的巴士完成。
在大型交通系统中，可以在两个相邻的行程中插入一个无头行程，以减少使用的公交车数量。
最近，由于公共交通市场的竞争日益激烈，保证足够的服务水平对公共交通公司来说变得至关重要。
许多调查报告称，准时对公交车乘客很重要，被认为是人们对公交车服务不满的主要原因之一（例如，Passenger Focus，2014；英国交通部，2011）。

传统上，公共交通公司在运营前几周完成车辆调度，目标是最小化计划总成本，包括车辆的固定成本以及闲置和旅行时间的可变成本。
然而，在运营当天，由于意外的需求激增和供应中断，道路交通状况可能表现出很大的不确定性，这可能会在道路建设和交通事故发生时出现（FHWA，2006）。
在随机出行时间下，公交车出行可能会因为交通拥堵而直接延误。
此外，延迟行程的迟到也可能导致其后续服务行程的延迟开始。
换句话说，延迟可以沿着由同一总线完成的相邻行程传播。
因此，道路交通状况的这种显着变化常常使旅行者遇到服务旅行的开始延迟，这大大降低了城市交通系统的性能。
为防止公交系统出现延误，可以在不同行程之间引入缓冲时间，但这不可避免地会增加公交车的空闲时间，导致系统成本的增加。

如今，许多城市的公交车辆都配备了全球定位系统，使公交机构能够实时监控公交运营情况。
利用来自这种自动车辆定位系统 (AVL) 的信息，已经进行了许多研究来增强公交车运营的控制策略（例如，Bie 等人，2015；Yu 等人，2016；Berrebi 等人，2017； Du 等人，2017 年）。
我们设想，信息和通信技术的快速发展也为智能调度公交车队提供了巨大的机会。
具体而言，一方面，通过 AVL 收集的数据可以极大地有助于了解不同的车辆时刻表如何影响随机行程时间下公交车队的运营。
另一方面，在一个运营日内，我们逐渐观察到行程的实际到达时间，从而可以动态调度车辆以完成后续行程。
在实践中，这种动态的车辆调度要求公交机构和公交车司机之间进行高效便捷的通信，由于通信技术的进步，这在技术上变得可行。

随机动态规划（SDP）被认为特别适用于不确定条件下的顺序决策问题。
通过正确选择状态和决策变量，我们能够制定用于动态调度公交车队的随机动态 VSP。
更具体地说，在所提出的随机动态车辆调度框架中，每次车辆重新调度时，我们不仅考虑了当前期间公交车队的运营情况，而且还考虑了重新调度对未来车队运营的影响，这是通过一个成本转移功能。
然而，由于行程时间随机性，所提出的 SDP 状态空间的增强与不确定的行程时间很容易导致“维度诅咒”，这被广泛引用为动态规划的致命弱点（例如，Powell，2007）。
为了应对这一挑战，我们采用了近似动态规划 (ADP) 方法，其中近似于成本函数，以便我们能够通过顺序求解多个混合整数线性程序来做出决策和求解贝尔曼方程。

我们论文的贡献包括：
(i) 我们在充分考虑延迟传播现象的情况下研究了随机旅行时间下的多站点 VSP；
(ii) 本研究是最早提出 ADP 方法以通过动态调度车辆来解决出行时间随机性、减少延误并最大限度地降低公交系统总成本的小组之一；
(iii) 我们没有预先假设行程时间和延误传播的任何概率分布或场景，并且在随机行程时间下调度策略对公交车队运营的影响是直接从多日运营数据集中学习的；
(iv) 我们使用北京公交线路的实际运营数据集来测试我们提出的框架，结果表明我们基于神经网络的 ADP 方法不仅表现出良好的学习行为，而且显着优于短视和静态策略。

对于其余部分，第 2 节回顾了有关 VSP 和 ADP 的文献。
第 3 节制定了随机动态 VSP。
在第 4 节中，我们提出了 ADP 框架。
第 5 节使用现实数据集来证明所提出的 ADP 框架的有效性并得出重要的见解。
最后，第 6 节总结了本文。

## 2 文献综述

### 2.1 公共交通中的车辆调度问题

公共交通规划流程从收集和预测乘客需求开始。
根据需求矩阵，地方当局然后设计公共交通网络的基础设施并规划线路及其频率（时间表）。
时间表上的每次旅行都有自己的出发和到达时间以及起点和终点站。
接下来，公共交通公司安排其车队来覆盖这些行程，并确保每次安排的行程都由一辆独特的车辆提供服务，这被广泛称为 VSP。
最后，需要执行船员调度。
为了最大限度地提高系统的生产力和效率，最好同时计划上述所有活动。
然而，由于这个规划过程极其复杂，特别是对于中型和大型车队，它需要对每项活动进行单独处理，将一项活动的结果作为下一项的输入（例如，Ceder，2007）。

车辆调度已经成为一个重要的研究领域大约 40-50 年（Bunte 和 Kliewer，2009），根据车辆段的数量可以分为两类。
单车厂车辆调度问题（SDVSP）表示只考虑一个车厂，而多车厂车辆调度问题（MDVSP）则考虑车辆驻扎在多个车厂。
在 MDVSP 中，车辆在运行一天后需要返回其起始站点，并且必须将某些行程分配给来自某个站点集合的车辆。
SDVSP 可在多项式时间内求解，并且已经提出了大量求解方法（例如，Saha，1970；Gertsbach 和 Gurevich，1977；Ceder，2016）。
然而，MDVSP 被证明是 NP-hard (Bertossi et al., 1987)。
已经提出了各种策略来减少模型变量的数量，例如采用时空图和列生成方法（例如，Ribeiro 和 Soumis，1994；Bodin 等，1983）。
精确算法（例如，Kliewer 等人，2006 年；Oukil 等人，2007 年）和启发式算法（例如，Ball 等人，1983 年）都已被开发来解决 MDVSP。
我们将感兴趣的读者推荐给 Desaulniers 和 Hickman (2007) 以及 Bunte 和 Kliewer (2009) 以获得最近的评论。

如前所述，出行时间的不确定性不可避免地会造成服务出行的延误。
为了确保公交系统的服务水平令人满意，公交系统运营商应考虑延误成本。
豪斯曼等人。 (2004) 在调度时采用二次函数来惩罚延迟，然后通过解决一系列优化问题并考虑未来旅行时间的不同场景，引入了动态调度方法。
瑙曼等人。 (2011) 在优化过程中考虑了典型的旅行时间场景，并最小化了计划旅行成本和延误造成的成本的预期总和。
Yan 和 Tang (2008) 开发了一个框架，将规划和实时阶段相结合，以解决随机公交出行时间下的城际公交路线和调度问题。
沉等人。 (2016) 假设行程时间遵循概率分布，然后他们设计了一个概率模型，其目标是最小化总成本以及最大化准点性能。
在车辆路径问题领域也可以找到类似的随机规划方法（例如，参见 Pillac 等人，2013 年的综合评论）。
然而，上述许多研究未能明确捕获沿相邻服务行程的延迟传播，这可能会对延迟成本产生重大影响。
此外，在有关延迟传播的现有研究中，很少有人进一步研究如何动态重新调度车队以减少和控制延迟传播效应。
最后，大规模的现实问题能否得到很好的解决仍然是一个悬而未决的问题。

### 2.2 近似动态规划

ADP 成为建模和解决大型复杂 SDP 的强大工具。
通过引入近似值函数（cost-to-go function），ADP能够分解大规模的SDP。
Powell (2007) 全面介绍了 ADP 的基本思想，并解决了 ADP 的关键算法问题。
在 ADP 领域已经提出了大量方法来解决现实问题，例如采用不同的值函数近似、更新规则以及探索与开发策略。
感兴趣的读者还可以参考 Bertsekas 和 Tsitsiklis (1996) 以及 Sutton 和 Barto (2018)。

ADP 的成功应用包括交通、金融、医疗、能源和供应链管理（例如，Fang 等人，2013；雷和欧阳，2017）。
例如，Papageorgiou 等人。
(2014) 使用 ADP 方法考虑了确定性海上库存路由问题 (MIRP)。
他们使用了一个价值函数近似值，它是一个可分离的分段线性连续函数，并引入了多周期前瞻策略。
Rivera 和 Mes (2017) 考虑了物流服务提供商面临的规划问题，即定期运输货物，他们使用了“基函数”方法和非平稳最小二乘法。
殷等人。
(2016) 考虑了具有不确定的时变乘客需求的地铁列车重新调度问题，他们利用了线性和可分离的基函数。

多层前馈神经网络作为非线性映射的强大且通用的近似器（Khosravi 等，2011）。
由于广泛的适用性，神经网络已被广泛用于 ADP 和强化学习领域，作为一种强大且适应性强的非线性形式的价值函数逼近 (Powell, 2007)。
当难以找到合适的基函数来捕获状态特征并且没有对非线性结构进行合理预测时，神经网络可以发挥重要作用。
具体来说，网络的输入是状态和动作的值，输出对应于 cost-togo 函数值。
这种方法已成功应用于各个领域。
张等人。 (2006) 采用多层前馈神经网络，在 Q-learning 中使用 levenberg-marquardt 反向传播算法进行训练，帮助驾驶员在复杂的交通情况下选择最佳路线。
米利科维奇等人。 (2013) 使用神经网络强化学习来开发和评估机器人机械手的视觉控制。
Hajizadeh 和 Mahootchi (2016) 使用径向基函数神经网络来近似美式期权的持续价值。

## 3 模型制定

本节致力于制定随机动态 VSP。
我们首先使用基于连接的模型（例如 Bunte 和 Kliewer，2009）描述静态 VSP。
我们采用有向图$J = ( N , A )$来表示VSP，如图[图 1](image/Fig1.png)，其中 Zand U 分别表示节点和链接的集合。
考虑到 MDVSP，我们将调度车辆的站点集表示为$K$。
在 MDVSP 中，必须将某些行程分配给来自特定车辆段的车辆 (Löbel, 1998)。
因此，每个仓库$k \in K$ 都有一个$J = (N,A)$ 的特定层$J^k (N^k, A^k)$。
节点集$N^k$k包括起始库$o^k$；终点站$d^k$；一组时间表行程，即$I^k$，每个行程对应一个预定出发时间和一个随机行程时间，并且必须由一辆巴士完成一次；一组虚拟站点，即$T^k$，它区别于真实站点节点 okand dkin 的感觉，即返回虚拟站点的公共汽车稍后将离开它并继续履行服务行程。
请注意，虚拟站点仅用于准确计算所使用的公交车数量，并且它们与其对应的实际站点共享相同的物理位置。
运营日开始时，虚拟车站没有公交车。
巴士在完成一些行程后来到虚拟站点，然后离开它们继续执行其他服务行程。
在这种情况下，要计算公交车队中的车辆数量，我们只需要计算从实际站点出发的车辆。
注意，在MDVSP中，$o^k$和$d^k$共享同一个物理位置，我们区分它们以方便制定。
为了始终保证从虚拟站点出发的公交车数量不超过可用公交车数量，虚拟站点节点进行了时间扩展，即$T^k$中的不同节点代表在不同时间返回虚拟站点。
在现实中，公交车可以随时到达一个虚拟站点，这导致我们网络中的虚拟站点节点数量无限。
为了减少计算工作量，每$\beta$ 分钟对时间进行一次采样。

![如图 1. 单周期 VSP 的示例 ](image/Fig1.png)

![如图 2.时间范围](image/Fig2.png)

弧集$A^k$ 包括死角、拉入和拉出弧。
令$e_{ij}, (i,j) \in A^k$代表从行程i的结束位置到行程j的开始位置的死角行程时间。
aian 和 bide 分别表示行程 i 的开始和结束时间。
车辆的调度对应于由节点和弧组成的路径。
车辆在同一个站点开始和结束，并且给定时间表的每次行程都由一辆车覆盖。
优化车辆的调度以最小化弧的总成本，包括旅行成本（所有弧）、等待时间成本（死角弧）、延迟成本（死角弧）和固定成本（拉入弧）。
等待时间成本来自公共汽车的提前到达。
在这种情况下，巴士必须在车站外的巴士站等候，直到下一次行程开始。
相比之下，延误成本是由于公交车晚到造成的，因此其下一次旅行无法按计划开始。
值得一提的是，VSP 的文献中广泛考虑了等待时间和延迟成本（例如，Huisman 等，2004；Kliewer 等，2006；Li，2013）。
车辆固定成本代表在公交车队中增加一辆车辆的成本。
请注意，在计算固定成本时，我们不计算从虚拟站点出发的车辆，因为这些成本已在这些车辆第一次使用时（在与相应实际站点相关的拉入弧中）计算在内。
如前所述，在运营的日子里，随着时间的推移，我们会观察到行程的实际到达时间，因此可以相应地重新安排车辆以完成后续行程。
在动态调度中，我们基于一个有限的计划范围，它被划分为几个时期。
在每个时期的开始，即$t=0,\dots,T$，我们根据当前的交通状况重新安排公交车队。
稍微滥用符号，我们还将从时间 ta 开始的时间段称为时间段 t，如图 [图 2](image/Fig2.png) 所示。
我们采用 Powell (2007) 中的物理过程。
在制定随机动态 VSP 之前，我们将介绍状态和决策变量、外生信息和转移函数。

### 3.1 状态

t时刻的系统状态，即${S_t} = (H_t,Q_t,P_t,G_t,R_t,U_t), t=0,\dots,T$，包括行程集合$H_t$、行程开始时间集合$Q_t$、行程结束时间集合$G_t$、分配车辆原发车点集合7t ，虚拟仓库$R_t$ 处可用车辆数量的集合，以及$U_t$ 弧的集合。
现在，我们详细介绍${S_t}$。
请注意，为了符号简单，我们省略了上标 kin [第 3.1-3.3 节](#31-state)。
在t时刻调度时，对于调度完成时间在$t+1$之前的行程，我们需要确定它们分配的车辆的下一次行程；否则，在完成行程后，这些车辆将空闲到$t+1$ 时间。
此外，对于在区间 t 期间开始的所有行程和在区间$t+1$ 期间开始的一些紧急行程，我们必须将它们分配到时间 t 的公交车，因为等到时间$t+1$ 将这些行程分配给公交车将导致巨大的延误成本（即使公交车是直接从车站发车的）。
为反映上述这些行程的差异，将t时刻的行程集合，即$H_t$，分为以下7个子集

* $N^t_1$ : 在时间 t 之前开始并在时间 t 之前已经分配给公交车的一组行程。直到时间 t 为止，尚未确定完成$N^t_1$ 后分配的公交车的下一次行程。
* $N^t_2$ : 在时间段 t 开始并在时间段 t 之前已经分配给公交车的一组行程。预定行程的结束时间在$t+1$时间之后。
* $\hat{N^t_2}$ : 在时间段 t 期间开始并在时间段 t 之前已经分配给公交车的一组行程。预定行程的结束时间在$t+1$时间之前。
* $N^t_3$ ：在时间 t 期间开始的一组行程，并且在时间 t 之前没有分配给公共汽车。预定行程的结束时间在$t+1$时间之后。
* $\hat{N^t_3}$ ：在时间 t 期间开始的一组行程，并且在时间 t 之前没有分配给公共汽车。预定行程的结束时间在$t+1$时间之前。
* $N^t_4$ ：在$t+1$ 期间开始的一组行程。它们必须在时间 t 分配给公共汽车。否则，如果我们等到$t+1$时间再将$N^t_4$中的那些行程分配给公交车，即使是直接从车站发车，也会产生巨大的延误成本。
* $N^t_5$ ：在$t+1$ 期间开始的一组行程。这些行程可以在 $t+1$ 的时间或时间分配给公共汽车。

如果我们将每个行程节点分成两个节点，分别代表相应行程的起点和终点，[图 3](pics/Fig3.png) 从概念上演示了上面的七个子集。

$Q_t$ 和$P_t$ 分别代表行程的开始和结束时间集合。 [^1]
具体来说，我们只考虑$N^t_1$行程的结束时间和$N_{2}^{t}$和$\widehat{N}_{2}^{t}$行程的开始时间，即$Q_{t}=\left\{a_{i}^{t} \mid i \in\left(N_{2}^{t} \cup \widehat{N}_{2}^{t}\right)\right\}$和$P_{t}=\left\{b_{i}^{t} \mid i \in N_{1}^{t}\right\}$。
注意，这归因于我们在$t$时获得的外生信息，我们将在3.2节中解释原因。
$G_{t}$用于跟踪分配的车辆对应的原车段，定义为$G_{t}=\left\{(i, k) \mid k \in K, i \in\left(N_{1}^{t} \cup N_{2}^{t} \cup \widehat{N}_{2}^{t}\right)\right\}$，其中行程$i$分配给原发车段$k$的车辆。
集合$R_{t}$为$\left\{r_{i}^{t} \mid i \in T\right\}$，其中$r_{i}^{t}$代表$t$时刻$i$虚拟仓库可调度的车辆数量。
最后，给出7个行程子集的定义，根据一条弧的起点和终点节点所属的子集，将弧集$U_{t}$分为11个子集，表示当前阶段可能的死区行程，即， $A_{1}^{t}=\left\{(i, j) \mid i \in N_{1}^{t}, j \in N_{3}^{t} \cup \widehat{N}_{3}^{t}\right\}, \quad A_{2}^{t}=\left\{(i, j) \mid i \in N_{1}^{t}, j \in N_{4}^{t}\right\}, \quad A_{3}^{t}=\left\{(i, j) \mid i \in N_{1}^{t}, j \in N_{5}^{t}\right\}, \quad A_{4}^{t}=\left\{(i, j) \mid i \in \widehat{N}_{2}^{t}, j \in N_{3}^{t} \cup \widehat{N}_{3}^{t}\right\}$、$A_{5}^{t}=\left\{(i, j) \mid i \in \widehat{N}_{2}^{t}, j \in N_{4}^{t}\right\}, \quad A_{6}^{t}=\left\{(i, j) \mid i \in \widehat{N}_{2}^{t}, j \in N_{5}^{t}\right\}, \quad A_{7}^{t}=\left\{(i, j) \mid i \in \widehat{N}_{3}^{t}, j \in N_{3}^{t} \cup \widehat{N}_{3}^{t}\right\}, A_{8}^{t}=\left\{(i, j) \mid i \in \widehat{N}_{3}^{t}, j \in N_{4}^{t}\right\}, \quad A_{9}^{t}=$、$\left\{(i, j) \mid i \in \widehat{N}_{3}^{t}, j \in N_{5}^{t}\right\}, A_{10}^{t}=\left\{(i, j) \mid i \in\left(N_{1}^{t} \cup \widehat{N}_{2}^{t} \cup \widehat{N}_{3}^{t}\right), j \in\{d\} \cup T\right\}$ 和$A_{11}^{t}=\left\{(i, j) \mid i \in\{o\} \cup T, j \in\left(N_{4}^{t} \cup N_{5}^{t} \cup N_{3}^{t} \cup \widehat{N}_{3}^{t}\right)\right\}$

[^1]：图 3 也展示了车场和虚拟车场的区别，即在运营日开始时，虚拟车场没有公交车。巴士在完成一些行程后来到虚拟站点，然后离开它们继续执行其他服务行程。

### 3.2 决策变量和外生信息

在运营当天，道路交通状况可能表现出很大的不确定性。
随着历史运营数据集的积累和旅行时间预测技术的发展，可以合理地假设在时间t，我们能够准确获取所有正在进行的旅行的结束时间信息，即$Q_t$和$P_t$（Huisman 等，2004；Yu 等，2011；Xu 和 Ying，2017）。
但是，对于尚未开始的行程，其行程时间是随机变量，等于 $p_i=\bar{p_i} + f(a_i) + \Delta_i$ ，
其中 pi 是行程 i 的实际旅行时间；
$\bar{p_i}$代表时间表上的预定行程时间；
$\Delta_i$是一个随机变量，反映道路交通状况的不确定性；
$f( a_i )$ 是一个函数，用于捕捉 aion the trip i 的行程时间的开始时间延迟的影响。
请注意，$f( a_i )$ 在线路频率较高的城市交通中可能很重要。
在城市环境中，如果行程开始较晚，则其行程时间可能会增加，因为如果这次行程没有延误，会有更多的乘客参加这次旅行，他们会选择下一次旅行（Huisman 等，2004）。
我们进一步注意到，为简单起见，我们假设空头旅行的旅行时间是恒定的。
扩展提议的框架以考虑随机死角行程时间是很简单的。
总而言之，表 1 分别显示了我们可以在时间 t 和 $t+1$ 获得的外生信息（行程时间信息）。

**表 1** 时间 t 和$t+1$ 的外生信息。

| |吨| t + 1 |
| ---- | ------------------- | -------------------------------- |
| Nt1 |开始和结束时间 | – |
| Nt2 |开始时间 |结束时间 |
| Nt2 |开始时间 |结束时间 |
| Nt3 | – |开始和结束时间 |
| Nt3 | – |开始和结束时间 |
| Nt4 | – |开始时间 |
| Nt5 | – |如果分配给公共汽车的开始时间|

![如图 4.行程集的过渡](image/Fig4.png)

公共交通公司在$t$时做出的决定可以用${X_t} = ( \cdots, x_{ij}^t, \cdots$表示，
其中$x_{ij}^t$ 是一个二进制变量，如果在$i$ 行程结束后派遣车辆完成行程$j$，则为1，否则为0。

### 3.3 过渡功能

转换包括更新行程和弧集、行程时间信息、分配的车辆站点和虚拟站点的可用公交车数量。
具体来说，在$t+1$ 时，$N^t_2$ 和$N^t_3$ 的行程将是$N_1^{t+1}$ 的成员；在时间 t 分配给公交车的$N^t_4$ 和$N^t_5$ 的行程将是$\hat{N_2}^{t+1}$ 或$N_2^{t+1}$ 的成员； $N^t_5$ 的行程，在时间 t 没有分配给公交车，将成为 $N_3^{t+1}$ 或 $\hat{N_3}^{t+1}$ 的成员。

[如图 4](image/Fig4.png) 具体演示了行程集的转换。
更新行程集$H_{t+1}$ 后，可以根据[3.2 节](#32-decision-variables-and-exogenous-information) 中的规范相应地定义弧集$U_{t+1}$。

关于如何获取表1$t+1$列中的行程时间信息，我们先让$a_i^{t+1} = a_i^t, i \in N_2^t \cup \hat{N_2}^t, b_i^{t+1} = b_i^{t}, i \in N_1^t$；
然后我们采用以下两个方程来更新休息时间信息。

$$
\begin{aligned}
&a_{i}^{t+1}=\max \left[\bar{a}_{i}, \sum_{(j, i) \in U^{t}} x_{j i}^{t}\left(b_{j}^{t+1}+e_{j i}\right)\right], i \in N_{3}^{t} \cup \widehat{N}_{3}^{t} \cup N_{4}^{t} \cup N_{5}^{t} \\
&b_{i}^{t+1}=a_{i}^{t+1}+\bar{p}_{i}+f\left(a_{i}^{t+1}\right)+\Delta_{i}, i \in N_{2}^{t} \cup \widehat{N}_{2}^{t} \cup N_{3}^{t} \cup \widehat{N}_{3}^{t}
\end{aligned}
$$

其中$\bar{a}_{i}$ 代表行程$i$ 在时间表上的预定开始时间。
按照上面的两个等式，在时间$t+1$，我们沿着车辆的预定路径递归更新行程的开始和结束时间。
通过这种方式，我们能够明确考虑沿同一车辆完成的不同行程的延迟传播。
更新相应的行程时间信息后，基于行程集的转换，我们可以得到$Q_{t+1}$和$P_{t+1}$，如图4所示。
要更新$G_{t+1}$，首先需要引入一个辅助集$\widetilde{G}_{t}$。
具体来说，让$\widetilde{G}_{t}=G_{t}$，我们递归地更新$\widetilde{G}_{t}$ 到$\widetilde{G}_{t}=\widetilde{G}_{t} \cup\left\{\left(i, \sum_{k \in K,(, k) \in \widetilde{G}_{t}} \sum_{(j, i) \in U^{t}} x_{j i}^{t} k\right)\right\}$。
请注意，此更新从集合$\left(N_{1}^{t} \cup N_{2}^{t} \cup \widehat{N}_{2}^{t}\right)$ 中的行程开始，并沿着车辆的预定路径继续。
更新$\widetilde{G}_{t}$后，我们可以根据行程集的转换关系，从$\widetilde{G}_{t}$中识别出$\left\{(i, k) \mid k \in K, i \in\left(N_{1}^{t+1} \cup N_{2}^{t+1} \cup \widehat{N}_{2}^{t+1}\right)\right\}$，即$G_{t+1}$，如图4所示。 关于$R_{t+1}$，我们通过$r_{i}^{t+1}=r_{i}^{t}+\sum_{j,(, i) \in U_{t}} x_{j i}^{t}-\sum_{j,(i, j) \in U_{t}} x_{i j}^{t}$ 更新它。
最后，为了更好地说明转换函数，我们在附录中提供了一个演示示例。

### 3.4 动态规划公式

动态调度的目标是最小化总成本，包括空头行驶时间成本、等待时间成本、车辆固定成本和延误成本。 [^2]
设$c_{d}$为单位行驶距离的成本，$\bar{d}_{i j}$为弧线的距离$(i, j)$，即空头行程$(i, j), c_{b}$为固定车辆成本，$c_{w}$为单位等待成本-时间。
类似于 Huisman 等人。 (2004) 为了反映长时间延误的巨大不利影响，我们采用二次惩罚函数来计算延误成本。
具体来说，假设延迟$\alpha$分钟的成本与固定车辆成本$c_{b}$相同，那么与行程的$r$分钟开始延迟相关的成本计算为$\left(r^{2} / \alpha^{2}\right) \cdot c_{b}$。
如果我们将$t$期间的成本表示为$C_{t}\left(\boldsymbol{S}_{t}, \boldsymbol{X}_{t}\right)$，我们可以通过$C_{t}\left(\boldsymbol{S}_{t}, \boldsymbol{X}_{t}\right)=c_{b} z^{t}+\sum_{k \in K} \sum_{(i j) \in U_{t}^{k}} x_{i j}^{k, t} c_{d} \bar{d}_{i j}+\sum_{i \in\left(N_{3}^{t-1} \cup \widehat{N}_{3}^{t-1} \cup N_{2}^{t} \cup \hat{N}_{2}^{t}\right)} \widetilde{c}_{i}^{t}+\sum_{i \in\left(N_{3}^{t-1} \cup \hat{N}_{3}^{t-1} \cup N_{2}^{t} \cup \hat{N}_{2}^{t}\right)} \widetilde{w}_{i}^{t}$来计算，其中$z^{t}$代表t期间新使用的车辆数量；
$\widetilde{c}_{i}^{t}$表示行程$i$的延迟成本，$\widetilde{w}_{i}^{t}$是行程$i$的等待时间成本。
注意$t$时刻，基于表1，我们只得到了$\left(N_{3}^{t-1} \cup \widehat{N}_{3}^{t-1} \cup N_{2}^{t} \cup \widehat{N}_{2}^{t}\right)$集合中行程的起始时间信息，这就解释了为什么$C_{t}\left(\boldsymbol{S}_{t}, \boldsymbol{X}_{t}\right)$中的延迟和等待时间成本只考虑了这些集合中的旅行。
根据上述符号，有限时间范围随机 VSP (S-VSP) 可以表示如下。

[^2]：注意，考虑到服务行程时间与调度优化无关，除了延迟的影响，即$f( a_i )$，总成本不包括服务行程时间成本。事实上，延误对服务行程时间的影响已经被计入延误成本。

$$
\begin{aligned}
&\min _{\boldsymbol{X}_{t}}\left\{\sum_{t=0}^{T} C_{t}\left(\boldsymbol{S}_{t}, \boldsymbol{X}_{t}\right)\right\} \\
&\sum_{j,(i, j) \in U_{t}^{k}} x_{i j}^{k, t}=1 \quad \forall i \in N_{1}^{t} \cup \widehat{N}_{2}^{t}, k \in K,(i, k) \in G_{t}, t \in\{0, \cdots, T\} \\
&\sum_{k} \sum_{i,(i)) \in U_{t}^{k}} x_{i j}^{k, t}=1 \quad \forall j \in \widehat{N}_{3}^{t} \cup N_{3}^{t} \cup N_{4}^{t}, t \in\{0, \cdots, T\} \\
&\sum_{k} \sum_{i,(i, j) \in U_{t}^{k}} x_{i j}^{k, t} \leq 1 \quad \forall j \in N_{5}^{t}, t \in\{0, \cdots, T\} \\
&\sum_{j,(, i) \in U_{t}^{k}} x_{j i}^{k, t}-\sum_{j,(i j) \in U_{t}^{k}} x_{i j}^{k, t}=0, \quad \forall i \in \widehat{N}_{3}^{t}, k \in K, t \in\{0, \cdots, T\} \\
&r_{i}^{t}+\sum_{j,(, i) \in \cup U_{t}^{k}} x_{j i}^{k, t}-\sum_{j,(i, j) \in U_{t}^{k}} x_{i j}^{k, t} \geq 0 \quad \forall k \in K, i \in T^{k}, t \in\{0, \cdots, T\} \\
&z^{t}=\sum_{k} \sum_{j,\left(0^{k}, j\right) \in U_{t}^{k}} x_{o^{k} j}^{k, t} \quad t \in\{0, \cdots, T\} \\
&x_{i j}^{k, t}=\{0,1\} \quad \forall i j \in U_{t}^{k}, k \in k, t \in\{0, \cdots, T\}
\end{aligned}
$$

按照公式，目标函数是在整个规划时间范围内最小化总成本的预期。
约束（1）保证车辆在$N_{1}^{t}$和$\widehat{N}_{2}^{t}$完成行程后不会停止，因为这些行程在时间$t+1$之前结束。
约束（2）确保$\widehat{N}_{3}^{t}, N_{3}^{t}$和$N_{4}^{t}$的行程被分配给$t$时间的车辆，因为等到$t+1$时间会导致巨大的延迟。
约束（3）意味着相应的弧可以在$t$ 或$t+1$ 处确定。
约束 (4) 是流量守恒约束，并为仓库构建连贯的路径。
约束条件（5）表示虚拟车厂出动车辆数量不能超过其剩余车辆数量。
约束（6）计算$t$期间新使用的车辆数量。
最后，约束 (7) 要求 $x_{i j}^{k, t}$ 是二进制的。

## 4 ADP算法开发

使用决策后状态变量，即在做出决策之后但在任何新信息到达之前的系统状态，用 • ta 表示，我们可以写出贝尔曼方程如下。

$$
V_{t}\left(\boldsymbol{S}_{t}\right)=\min _{\boldsymbol{X}_{\boldsymbol{t}}}\left[C_{t}\left(\boldsymbol{S}_{\boldsymbol{t}}, \boldsymbol{X}_{\boldsymbol{t}}\right)+V_{t}^{a}\left(\boldsymbol{S}_{\boldsymbol{t}}^{\boldsymbol{a}}\right)\right]
$$

英石。约束 (1) - (7)

其中$V_{t}^{a}\left(\boldsymbol{S}_{t}^{a}\right)=E\left\{V_{t+1}\left(\boldsymbol{S}_{t+1}\right) \mid \boldsymbol{S}_{t}, \boldsymbol{X}_{t}\right\}$是我们做出决定后立即处于$\boldsymbol{S}_{t}^{a}$状态的期望值，即cost-togo函数。
S-VSP 可以使用经典的反向动态规划算法通过递归求解贝尔曼方程来求解。
然而，向后动态规划面临着维数的诅咒，并且在计算上可能变得难以处理。
例如，如果有 500 次行程、2 个站点和 9 个时段，则每次我们做出决定时大约有 2000 条可能的弧线。
由于决策变量是二元的，动作空间可能有$2^{18000}$ 个结果。
此外，当考虑延迟传播时，状态和结果空间可能更大。为了应对这些挑战，我们采用了 ADP 方法，这是解决大规模动态程序的强大工具。

在 ADP 方法中，我们不是在时间上后退，而是使用近似值函数来替换贝尔曼方程中的值函数$V_t^a(S_t^a)$，并及时前移做出决策。
下一个状态是依赖于当前决策和样本路径的随机变量，它是根据具有观察到的随机信息的转移函数确定的。
随着算法的进展，使用访问状态的已实现值更新值函数近似值。
这样的过程迭代运行，每次使用新采样的实现，逐渐达到更准确的近似值函数和更好的策略。

在以下小节中，我们首先分析成本函数的组成，然后使用神经网络提出价值函数近似值。
然后，我们使用随机梯度方法按照 TD $(\lambda)$ 程序更新近似值。
为了提高 ADP 方法的性能，稍后将讨论一些关键的算法问题，例如步长规则和探索 *vs.* 开发。

### 4.1 值函数近似

$V_{t}^{a}\left(\boldsymbol{S}_{t}^{a}\right)$ 是处于状态$\boldsymbol{S}_{t}$ 并采取行动$\boldsymbol{X}_{t}$ 的最佳预期未来成本。
如前所述，在ADP方法中，我们提出了一个函数$\bar{V}_{t}^{a}\left(\boldsymbol{S}_{t}^{a}\right)$来近似值函数$V_{t}^{a}\left(\boldsymbol{S}_{t}^{a}\right)$。
考虑到决策变量$\boldsymbol{X}_{t}$ 是二元的，线性或分段线性函数形式可能不适合$\bar{V}_{t}^{a}\left(\boldsymbol{S}_{t}^{a}\right)$。
具体来说，难以构建决策后变量$\boldsymbol{S}_{t}^{a}$，使用车辆调度计划$\boldsymbol{X}_{t}$和$\boldsymbol{S}_{t}$中的行程时间信息；所以我们改用状态-动作对。
换句话说，$V_{t}^{a}\left(\boldsymbol{S}_{t}^{a}\right)$的输入同时包含二元决策和行程时间信息，这意味着我们需要用二元变量和连续变量的输入找到合适的$\bar{V}_{t}^{a}\left(\boldsymbol{S}_{t}^{a}\right)$。
这与之前采用分段线性近似值函数的许多研究不同（例如，Godfrey 和 Powell，2001、2002）。

![如图 5. 近似值函数的三层神经网络](image/Fig5.png)

为了提高准确性，我们考虑更复杂的值函数近似。神经网络在 ADP 中广泛用作价值函数逼近的一类强大且适应性强的非线性形式，提供更灵活的框架组，并且还可以递归更新（例如，Zhang et al., 2006; Powell, 2007; Hajizadeh and马胡奇，2016 年）。在本研究中，我们使用三层前馈神经网络来近似$V_{t}^{a}\left(\boldsymbol{S}_{t}^{a}\right)$，如图 5 所示。三层前馈神经网络输入层接收的神经元包括：(i)决策变量$\boldsymbol{X}_{t}$； (ii) 状态变量$P_{t}$，即$\left(b_{i}^{t}-t \cdot L\right.$)$/ L, i \in N_{1}^{t}$； (iii) 状态变量$Q_{t}$，即$\left(a_{i}^{t}-t \cdot L\right) / L, i \in N_{2}^{t} \cup \widehat{N}_{2}^{t}$，其中$L$代表一个时间段的持续时间。输出神经元是价值函数的估计值$V_{t}^{a}\left(\boldsymbol{S}_{t}^{a}\right) .$Relu 函数用于激活感知器节点。

设$F_{q}^{l, t}$代表神经网络$l$层的输入单元$q$，$\Gamma^{l}$代表神经网络$l$层的输入单元集合。前面提到过，向量$\left(\cdots F_{q}^{1, t}, \cdots\right), q \in \Gamma^{1}$，包括了上面三种接收的神经元。采用的三层前馈神经网络的特点如下。

$$
\begin{aligned}
&Y_{q}^{2, t}=\sum_{q \in \Gamma^{1}} W_{q, q}^{1, t} \cdot F_{q}^{1, t}+v_{q}^{1, t} \quad \forall q \in \Gamma^{2} \\
&F_{q}^{2, t}=\max \left(0, Y_{q}^{2, t}\right) \quad \forall q \in \Gamma^{2} \\
&\nabla_{t}^{a}\left(\boldsymbol{S}_{t}^{a}\right)=\sum_{q \in \Gamma^{2}} W_{q}^{2, t} F_{q}^{2, t}+v^{2, t}
\end{aligned}
$$

其中$W_{q, q}^{1, t}$表示第1层单元$q$和$2 ; W_{q}^{2, t}$层单元$q$之间的权重是$2 ; v^{1, t}$和$v^{2, t}$层输入单元$q$关联的权重分别是第 1 层中单位 $q$ 的偏差和第 2 层中的偏差。约束(9)使用Relu函数激活@194​​@。约束 (10) 定义了近似值函数。请注意，随着 ADP 算法的进行，参数$W_{q, q}^{1, t}, W_{q}^{2, t}, v_{q}^{1, t}$ 和$v^{2, t}$ 将使用访问状态的实现值迭代更新。根据上述基于神经网络的近似函数，贝尔曼方程可以重新表述如下。

$$
V_{t}\left(\boldsymbol{S}_{t}\right)=\min _{\boldsymbol{X}_{t}}\left[C_{t}\left(\boldsymbol{S}_{t}, \boldsymbol{X}_{t}\right)+\bar{V}_{t}^{a}\left(\boldsymbol{S}_{t}^{a}\right)\right]
$$

英石。约束 (1) - (10)
通过这种方式，我们绕过了贝尔曼方程中的嵌入期望。请注意，将上述模型重新表述为混合整数线性规划是很简单的，为了简洁起见，我们不提供它。

### 4.2 值函数更新

定义$\boldsymbol{\Theta}=\left(\cdots, W_{q_{1}, q_{2}}^{1, t}, \cdots, W_{q_{3}}^{2, t}, \cdots, v_{q_{4}}^{1, t}, \cdots v^{2, t}, \cdots\right), \forall q_{1} \in \Gamma^{1}, q_{2}, q_{3}, q_{4} \in \Gamma^{2}$。
我们采用随机梯度算法更新$\boldsymbol{\Theta}$（e.g., Powell, 2007; Fang et al., 2013），如下所示。

$$
\Theta^{m}=\Theta^{m-1}-\alpha_{m-1}\left(\bar{V}_{t}^{a, m-1}\left(\boldsymbol{S}_{t}^{a}\right)-\widehat{v}_{t+1}\right) \nabla_{\Theta} \bar{V}_{t}^{a, m-1}\left(\boldsymbol{S}_{t}^{a}\right)
$$

其中上标$m$代表迭代次数； $\alpha_{m-1}$是迭代步长$m-1 ; \hat{v}_{t+1}$是当前策略和样本路径产生的实现值； $\nabla_{\Theta} \bar{V}_{t}^{a, m-1}\left(\boldsymbol{S}_{t}^{a}\right)$表示在迭代$m-1$时近似值函数相对于参数向量$\boldsymbol{\Theta}$的梯度。
具体来说，$\nabla_{\Theta} \bar{V}_{t}^{a, m-1}\left(\boldsymbol{S}_{t}^{a}\right)$ 可以根据方程计算。 (8)-(10) 使用链式法则。 [^3] 对于$\left(\bar{V}_{t}^{a, m-1}\left(\boldsymbol{S}_{t}^{a}\right)-\hat{v}_{t+1}\right)$的计算，我们采用时间差分法，如下图所示。

[^3]：注意因为函数$F_{q}^{2, t}$在$Y_{q}^{2, t}=0 .$处不可微，所以我们使用它的次梯度来方便$\nabla_{\Theta} \bar{V}_{t}^{a, m-1}\left(\boldsymbol{S}_{t}^{a}\right)$的计算。

$$
\hat{v}_{t}=\bar{V}_{t-1}^{a, m-1}\left(\boldsymbol{S}_{t-1}^{a}\right)+\sum_{\tau=t}^{T} \lambda^{\tau-t}\left[C_{\tau}\left(\boldsymbol{S}_{\tau}^{m-1}, \boldsymbol{X}_{\tau}^{m-1}\right)+\bar{V}_{\tau}^{a, m-1}\left(\boldsymbol{S}_{\tau}^{a}\right)-\bar{V}_{\tau-1}^{a, m-1}\left(\boldsymbol{S}_{\tau-1}^{a}\right)\right]
$$

上面的等式产生了$\operatorname{TD}(\lambda)$更新方法，在ADP领域被广泛采用。如果我们将$\left[C_{\tau}\left(\boldsymbol{S}_{\tau}^{m-1}, \boldsymbol{X}_{\tau}^{m-1}\right)+\bar{V}_{\tau}^{a, m-1}\left(\boldsymbol{S}_{\tau}^{a}\right)-\bar{V}_{\tau-1}^{a, m-1}\left(\boldsymbol{S}_{\tau-1}^{a}\right)\right]$ 视为对价值函数估计的修正，则使用贴现因子$0 \leq \lambda \leq 1$ 来反映沿着样本路径更远的更新不应该像路径中更早的更新那样给予如此大的权重。

### 4.3 步长规则

ADP 算法中的一个重要问题是选择合适的步长规则，因为它对收敛性和求解性能有显着影响。
由于各种已实现和收集的数据缺乏变化，确定性步长规则可能会导致收敛速度缓慢。
在本研究中，我们对均值稳定增加或减少的非平稳数据采用最佳随机步长规则，即偏差调整卡尔曼滤波器 (BAKF) 步长规则（例如，George 和 Powell，2006； Powell，2007 年；Fang 等人，2013 年），由 给出。

$$
\alpha_{m-1}=1-\frac{\bar{\sigma}^{2}}{\left(1+\varkappa_{m-1}\right) \bar{\sigma}^{2}+\left(\eta_{m}\right)^{2}}
$$

其中$\bar{\sigma}^{2}$表示$\bar{V}_{t}^{a, m}\left(\boldsymbol{S}_{t}^{a}\right)$的方差估计，$\eta_{m}$表示对非平稳数据使用简单平滑的偏差估计；最后，$x_{m-1}$ 是使用$\chi_{m}=\left\{\begin{array}{cc}\left(\alpha_{m-1}\right)^{2} & m=1 \\ \left(1-\alpha_{m-1}\right)^{2} \kappa_{m-1}+\left(\alpha_{m-1}\right)^{2} & \mathrm{~m}>1\end{array} .\right.$ 计算的。有关更多详细信息，请参阅Powell (2007) 中的$11.4$ 部分。

### 4.4 探索与开发

使用修改后的混合探索策略，因为我们可能会忽略一些在我们没有经常访问它们时可能看起来不吸引人的状态和动作。
探索率设置为迭代次数 m 的分段线性函数。
在早期迭代中，我们随机探索更多状态以更新值函数近似值的不准确初始化，而在后期迭代中，我们利用状态值的当前估计来获得我们认为最好的决策。
在数值研究部分，我们将研究各种勘探率的表现。
最后，所提出的ADP算法框架的详细过程如下所示。

![ADP算法框架](image/ADP_algorithmic_framework.png)

## 5 数值例子

在本节中，我们基于北京公交线路的实际运营数据集进行数值示例。
具体而言，我们提取了 2015 年 10 月 1 日至 15 日期间北京 11 条公交线路和 2 个站点每天重复 520 次的实际出行时间。
第一次旅行从 7:00 开始，最后一次旅行从 22:00 开始。
基于数据集的服务行程的实际出行时间，我们将每个决策周期的持续时间设置为 110 分钟，[^4] 并相应地将规划范围划分为 9 个周期。
我们使用短视和静态策略作为基准。
短视政策没有考虑未来的影响，只根据当期成本做出短视的决定。
静态策略在运营日开始之前优化整个规划范围内的公交车队的时间表，并实施获得的时间表，而不管公交车队在白天的运营状况如何。
这些算法是用 C++ 和 Microsoft Visual Studio 2012 编程的。
所有计算实验均在配备 Intel(R) Core(TM) i5-4460 CPU@3.20 GHz 和 16 GB RAM 的计算机上进行。
为了模拟出行时间的随机性，我们首先根据现实数据集计算每次出行持续时间的平均值，然后假设出行的实际出行时间遵循截断正态分布，范围从 60% 到 140%其计算平均值，标准偏差等于其平均值的 20%。
最后，除非另有说明，所有其他参数值均根据 Huisman 等人的规范设置。
(2004)。

[^4]：在动态调度过程中，一个时段的合适时长应大于一次行程的行程时间，短于连续两次行程的总行程时间。如果持续时间太长，我们无法及时调整时间表。如果持续时间太短，重新调度发生的频率太高，其效果是有限的。最后，我们注意到选择 110 min 还考虑了避免多次旅行的开始时间的因素。

### 5.1 收敛

使用BAKF步长规则[^5]，并为前200次迭代设置$\rho=0.1$和$\lambda=0.2$，我们绘制了图6中520次行程情况下ADP方法的收敛曲线。
每次迭代的平均计算时间为$23.26 \mathrm{~s}$，收敛大约需要$4652.66 \mathrm{~s}$。
在图6中，顶部曲线描绘了不同迭代次数下实现的总成本；中间曲线表示不包括第一期成本的已实现总成本的变化；底部曲线代表不同迭代次数下$\bar{V}_{0}^{a}\left(\boldsymbol{S}_{0}^{a}\right)$的值。可以观察到，随着迭代次数的增加，近似值函数$\bar{V}_{0}^{a}\left(\boldsymbol{S}_{0}^{a}\right)$逐渐逼近不包括第一期成本的实现总成本，并且总实现成本降低，这证明了我们提出的ADP方法的有效性根据随机行程时间安排车队。
请注意，底部曲线接近中间曲线而不是顶部曲线，因为我们在 ADP 方法中使用了决策后状态，$\bar{V}_{0}^{a}\left(\boldsymbol{S}_{0}^{a}\right)$ 是从第二个时期到操作范围结束的价值函数的近似值。

### 5.2 ADP 和基准政策的比较

为了将 ADP 方法与静态和近视策略进行比较，我们进一步从 520 个行程中提取了 87 个行程，以便静态策略下的基于连接的模型，即 MDVSP，可以由 CPLEX 等商业求解器直接准确地求解。
我们首先针对近视、静态和 ADP 策略模拟 150 次。
ADP策略使用迭代收敛后得到的近似值函数，我们设置0 0.1和0 0.4。
对于静态策略，我们引入了 30 分钟的缓冲时间，以便延迟传播不会导致极大的延迟成本。
表2比较了这三种政策在不同相对标准差值下实现总成本的平均值。
相对标准差对应于随机出行次数的分布；例如，0.2 表示标准偏差值等于平均值​​的 20%。
可以观察到，随着行程时间的随机性增加，ADP 方法相对于两种基准策略的优势变得更加显着。
无花果。
图 7 和图 8 分别描绘了在一次模拟中根据 ADP 和短视政策得出的公交车队时刻表，相对标准偏差为 0.2。
通过检查这些公交车队时刻表的详细信息，我们可以总结出 ADP 政策优于短视政策的一些原因。

* 近视策略仅根据当期成本选择动作。在重新安排时，它经常无法考虑从虚拟站点到旅行的旅行成本，因为这些成本可能不属于当前时期。结果，观察到近视策略过于频繁地发送总线返回虚拟站点，如图8所示。
* ADP政策考虑了未来时期潜在的延误成本，因此选择了相对保守的死角行程，即图7中一些虚线的斜率低于图1中的斜率。
* 在 MDVSP 中，一些后期开始的行程只能由特定站点的巴士完成。短视策略在前期调度时没有考虑到这个因素，因为它只关注当期的操作。因此，一些前期发车的公交车在后期的利用率相对较低，因为库区限制使它们无法提供多次服务，从而导致资源浪费。请注意，这一点不能通过比较图 3 和图 6 直接观察到。 7 和 8，但检查详细的时间表可以揭示它。

表 3 比较了静态和 ADP 模型的平均实现操作和延迟成本，相对标准偏差为 0.2。
我们观察到，与静态策略相比，ADP 的优势主要归功于其显着降低延迟成本的能力。

### 5.3 探索与开发

在提出的 ADP 算法中，我们在前 200 次迭代中以固定概率随机选择一个动作。
之后，我们停止探索并根据我们学到的价值函数选择最小化总成本的确切动作。
我们将 ADP 算法的性能与表 4 中的各种值进行了比较。图 9 显示了它们的收敛曲线。
在表 4 中，我们可以观察到，= 0.1 的 ADP 算法很好地平衡了勘探和开发，产生了更好的解决方案，收敛后波动较小。
可能的解释是，当探索率过低时，价值函数收敛的时间较短，但由于忽略了许多可能的状态，得到的策略效率不够高；当探索率过高时，会探索很多不必要的状态，导致价值函数难以收敛。

[^5]：我们在早期迭代中使用谐波步长规则，当我们无法准确计算 BAKF 步长时，如 Powell (2007) 中介绍的那样，以减少计算时间。

![图6。使用神经网络的 ADP 收敛曲线](image/fig6_s.png)

**表 2** ADP 和基准政策下平均实现总成本的比较

|相对标准偏差 | ADP |静态 |近视 |
| --------------------------- | --------- | --------- | --------- |
| 0.1 | 111972.71 | 121037.94 | 118743.03 |
| 0.2 | 121602.28 | 159911.86 | 129679.47 |
| 0.3 | 124303.41 | 192940.28 | 135789.57 |

![图7.ADP政策下的时间表时空图](image/Fig7.png)

![图8.近视政策下的时间表时空图](image/Fig8.png)

**表 4** 不同 ρ 的性能。

| | ρ= 0 | ρ= 0.1 | ρ= 0.2 | ρ= 0.3 |
| ------------------ | --------- | --------- | --------- | --------- |
|平均值 | 610821.15 | 606602.90 | 618326.46 | 619443.61 |
|标准差 | 2882​​8.24 | 27088.33 | 30863.99 | 28891.38 |

![图9.不同ρ率下的收敛曲线](image/fig9_s.png)

![图10。不同λ值下的收敛曲线](image/fig10_s.png)

**表 5** 不同 .

| | λ= 0 | λ= 0.2 | λ = 0.4 | λ = 0.6 |
| ------------------ | --------- | --------- | --------- | --------- |
|平均值 | 624124.23 | 606602.90 | 617035.21 | 619894.42 |
|标准差 | 35089.91 | 27088.33 | 31013.16 | 28779.52 |

### 5.4 λ的影响

回想一下，我们通过$TD(\lambda)$的方法更新值函数，即神经网络。
$TD(\lambda)$ 的性能受折扣因子值的影响。
不同值下的收敛曲线如图 1 所示。
10 及其性能比较见表 5。
在表 5 中，很明显，$TD(\lambda)$ 方法=0.2 提供了更好的解决方案，收敛后波动较小。
事实上，如果 的值太高，过多地考虑当前动作对未来总成本的影响可能会误导政策，因为在早期迭代中近似值函数不够准确。
如果 的值太低，由于我们没有足够关注未来的成本，近似值函数收敛缓慢。
最后，为了让读者更好地理解图。
在图 9 和 10 中，我们计算每 50 次迭代的已实现总成本的平均值，并根据附录中的计算平均值绘制收敛趋势。

## 6 结论

在本文中，我们提出了在充分考虑延迟传播效应的情况下，在随机旅行时间下求解 MDVSP 的 ADP 方法。
拟议的框架动态指导公交车队的运营以应对复杂的交通状况，并综合考虑公交系统的运营成本和准点率。
特别是，利用三层前馈神经网络逼近一个值函数，可以有效降低问题的规模和复杂度，我们能够通过顺序求解多个MIP问题来进一步决策和求解Bellman方程。
随着 ADP 算法的进展，使用访问状态的已实现值并遵循随机梯度算法和$TD(\lambda)$ 方法更新值函数近似值。
基于北京公交线路实际运营数据集的数值例子表明，与近视和静态策略相比，我们基于神经网络的 ADP 方法不仅表现出良好的学习行为，而且在解决大规模实际问题方面表现更好，特别是当行程时间随机性很高时。
未来的研究将集中在扩展所提出的框架以考虑随机交通条件下替代燃料车辆的调度问题。
与传统燃料柴油公交车的 VSP 相比，替代燃料 VSP 需要额外考虑范围限制和充电计划，这将不可避免地增加模型复杂度并带来计算挑战（例如，Chao and Chen，2013；Adler et等，2016）。

## 致谢

该研究得到了国家自然科学基金 (51622807, 71501107, U1766205) 的部分资助。
该研究得到了清华大学工业工程系以数据为中心的管理中心的部分支持。
作者要感谢匿名审稿人的有益评论和建议。

## 附录 A

在本附录中，我们首先提供一个简单的例子来说明转移函数，如图 A1 所示。
行程时间

![图A1.简单的例子来说明过渡功能](image/FigA1.png)

**表 A1** 行程时间信息。

|旅行 |预定开始时间 |预定结束时间 |随机变量（分钟）|
| ---- | -------------------- | ------------------ | --------------- |
|我| 8:00 | 8:50 | 25 |
| j | 9:10 | 10:00 | -10 |
| k | 11:10 | 12:00 | 10 |

信息如表A1所示，其中预先定义了行程的预定开始和结束时间，并逐渐观察随机变量的值，即$\Delta_{i}$，如表1所示。假设这些行程之间的死角行程时间都设置为$20 \mathrm{~min}$，公交车从车站到行程起点$j$或$k$需要$25 \mathrm{~min}$。时间$t-1, t$ 和$t+1$ 分别对应于7:10、9:00 和10:50。

当我们在时间$t-1$ 安排行程时，行程$j$ 属于集合$N_{4}^{t-1}$，因为如果我们将它分配给位于时间$t$。假设在$t-1$时刻，我们调度一辆公交车先完成行程$i$，然后是行程$j$。随着时间的推移，我们观察到$\Delta_{i}$的值，行程$i$准时开始。在$t$时刻，行程$i$的结束时间使用$b_{i}^{t}=a_{i}^{t}+\bar{p}_{i}+f\left(a_{i}^{t}\right)+\Delta_{i}$更新，其中$f\left(a_{i}^{t}\right)=0$因为行程$i$准时开始，我们有$b_{i}^{t}=9: 15$。然后使用$a_{j}^{t}=\max \left\{9: 10, b_{i}^{t}+20\right.$ mins $\}=9: 35$ 更新行程$j$ 的开始时间。假设$f\left(a_{j}^{t}\right)=0.2\left(a_{j}^{t}-\bar{a}_{j}\right)$，这意味着25 分钟的启动延迟将导致5 分钟的额外行驶时间。当我们在时间$t$安排行程时，行程$j$属于$\widehat{N}_{2}^{t}$，假设我们在完成行程$j$后调度巴士去完成行程$k$。在$t+1$ 时，行程$j$ 的结束时间使用$b_{j}^{t+1}=9: 35+(5+40) \operatorname{mins}=10: 20$ 更新。同样，$a_{k}^{t+1}=\max \left(11: 10, b_{j}^{t+1}+20\right.$ 分钟$)=11: 10$。最后，行程$j$'s 和$k$'s 对应的depot 被更新为与行程$i$'s 相同的一个。

接下来，为了让读者更好地理解图。在图 9 和图 10 中，我们计算每 50 次迭代的已实现总成本的平均值，并根据计算出的平均值绘制收敛趋势。 A2 和 A3。

![如图 A2。不同ρ率下的收敛趋势](image/figA2_s.png)

![如图 A3.不同λ值下的收敛趋势](image/figA3_s.png)

## 参考文献

移除